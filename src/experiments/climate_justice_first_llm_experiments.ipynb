{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate justice experiments\n",
    "The goal of this notebook is to find out (in a very rough first experiment kind of way) how well different model set-ups are able to pick up on fairly subtle concepts such as different justice theories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "This is staken more or less directly from the open data repository. For these experiments, we're only really interested in a small subset, so loading the whole dataset, only to then subset it to a few dozen is sort of overkill. So at the end of this, I'll write the subset to a little csv to use instead. Keeping the code to do so here anyway so it's easy to replicate if you don't have that csv. \n",
    "\n",
    "If you do have a justice_subset.csv already, just set reload_data to False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_data = False\n",
    "create_new_sample_csv = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from huggingface_hub import snapshot_download\n",
    "import tqdm as notebook_tqdm\n",
    "import pandas as pd\n",
    "\n",
    "#Using the public version of the repo for now\n",
    "REPO_NAME = \"ClimatePolicyRadar/all-document-text-data\"\n",
    "REPO_URL = f\"https://huggingface.co/datasets/{REPO_NAME}\"\n",
    "DATA_CACHE_DIR = \"../../cache\"\n",
    "\n",
    "REVISION = \"main\"  # Use this to set a commit hash. Recommended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reload_data:\n",
    "    snapshot_download(\n",
    "        repo_id=REPO_NAME,\n",
    "        repo_type=\"dataset\",\n",
    "        local_dir=DATA_CACHE_DIR,\n",
    "        revision=REVISION,\n",
    "        allow_patterns=[\"*.parquet\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(): \n",
    "    db = duckdb.connect('data.db')  # Create a persistent database\n",
    "\n",
    "    # Authenticate (only needed if loading a private dataset)\n",
    "    # You'll need to log in using `huggingface-cli login` in your terminal first\n",
    "    #db.execute(\"CREATE SECRET hf_token (TYPE HUGGINGFACE, PROVIDER credential_chain);\")\n",
    "\n",
    "    # Drop the existing table if it exists (necessary if you want to update the fields)\n",
    "    db.execute(\"DROP TABLE IF EXISTS open_data\")\n",
    "\n",
    "    # Check if table exists\n",
    "    table_exists = db.execute(\"SELECT COUNT(*) FROM information_schema.tables WHERE table_name = 'open_data'\").fetchone()[0] > 0\n",
    "\n",
    "    if not table_exists:\n",
    "        # Create a persistent table with only the columns we need\n",
    "        db.execute(\"\"\"\n",
    "            CREATE TABLE open_data AS \n",
    "            SELECT \n",
    "                \"document_metadata.geographies\",\n",
    "                \"document_metadata.corpus_type_name\",\n",
    "                \"document_metadata.publication_ts\",\n",
    "                \"document_metadata.import_id\",\n",
    "                \"document_metadata.translated\",\n",
    "                \"document_metadata.source_url\",\n",
    "                \"document_metadata.document_title\",\t\n",
    "                \"text_block.text\",\n",
    "                \"text_block.language\",\n",
    "                \"text_block.type\",\n",
    "                \"text_block.index\",\n",
    "                \"text_block.page_number\"\n",
    "            FROM read_parquet('{}/*.parquet')\n",
    "        \"\"\".format(DATA_CACHE_DIR))\n",
    "\n",
    "        # Create indexes for common query patterns\n",
    "        db.execute(\"CREATE INDEX idx_language ON open_data(\\\"text_block.language\\\")\")\n",
    "        db.execute(\"CREATE INDEX idx_corpus_type ON open_data(\\\"document_metadata.corpus_type_name\\\")\")\n",
    "        db.execute(\"CREATE INDEX idx_publication_ts ON open_data(\\\"document_metadata.publication_ts\\\")\")\n",
    "        db.execute(\"CREATE INDEX idx_text_type ON open_data(\\\"text_block.type\\\")\")\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a subset of fairly recent documents based on title keywords, including a few hand-picked documents\n",
    "if reload_data:\n",
    "    db = create_db()\n",
    "    title_df = db.sql(\n",
    "        \"\"\"\n",
    "    SELECT *\n",
    "    FROM open_data\n",
    "    WHERE (\n",
    "        LOWER(\"document_metadata.document_title\") LIKE '%justice%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%just transition%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%human rights%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%ethical%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%fwg inputs to the technical assessment%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%climate equity%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%a fair climate%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%reducing inequalities%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%iisd%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%climate analytics%'\n",
    "        OR LOWER(\"document_metadata.document_title\") LIKE '%inflation reduction act%'\n",
    "    )\n",
    "    AND \"document_metadata.publication_ts\" >= '2018-01-01'\n",
    "    AND \"document_metadata.import_id\" IS NOT NULL\n",
    "    AND \"document_metadata.source_url\" IS NOT NULL\n",
    "        \"\"\"\n",
    "        ).to_df()\n",
    "\n",
    "\n",
    "    title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nr of paras: 41944\n",
      "Total nr of documents: 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geographies</th>\n",
       "      <th>corpus_type_name</th>\n",
       "      <th>publication_ts</th>\n",
       "      <th>import_id</th>\n",
       "      <th>translated</th>\n",
       "      <th>source_url</th>\n",
       "      <th>document_title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>type</th>\n",
       "      <th>index</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ZAF']</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>2020-09-09T00:00:00Z</td>\n",
       "      <td>CCLW.document.i00000012.n0000</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pccommissionflo.imgix.net/uploads/imag...</td>\n",
       "      <td>Just Transition Framework</td>\n",
       "      <td>Call</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ZAF']</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>2020-09-09T00:00:00Z</td>\n",
       "      <td>CCLW.document.i00000012.n0000</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pccommissionflo.imgix.net/uploads/imag...</td>\n",
       "      <td>Just Transition Framework</td>\n",
       "      <td>PRESIDENTIAL CLIMATE COMMISSION TOWARDS A JUST...</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ZAF']</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>2020-09-09T00:00:00Z</td>\n",
       "      <td>CCLW.document.i00000012.n0000</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pccommissionflo.imgix.net/uploads/imag...</td>\n",
       "      <td>Just Transition Framework</td>\n",
       "      <td>ERO</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ZAF']</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>2020-09-09T00:00:00Z</td>\n",
       "      <td>CCLW.document.i00000012.n0000</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pccommissionflo.imgix.net/uploads/imag...</td>\n",
       "      <td>Just Transition Framework</td>\n",
       "      <td>BOMBELA</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ZAF']</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>2020-09-09T00:00:00Z</td>\n",
       "      <td>CCLW.document.i00000012.n0000</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pccommissionflo.imgix.net/uploads/imag...</td>\n",
       "      <td>Just Transition Framework</td>\n",
       "      <td>June 2022</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geographies   corpus_type_name        publication_ts  \\\n",
       "0     ['ZAF']  Laws and Policies  2020-09-09T00:00:00Z   \n",
       "1     ['ZAF']  Laws and Policies  2020-09-09T00:00:00Z   \n",
       "2     ['ZAF']  Laws and Policies  2020-09-09T00:00:00Z   \n",
       "3     ['ZAF']  Laws and Policies  2020-09-09T00:00:00Z   \n",
       "4     ['ZAF']  Laws and Policies  2020-09-09T00:00:00Z   \n",
       "\n",
       "                       import_id  translated  \\\n",
       "0  CCLW.document.i00000012.n0000       False   \n",
       "1  CCLW.document.i00000012.n0000       False   \n",
       "2  CCLW.document.i00000012.n0000       False   \n",
       "3  CCLW.document.i00000012.n0000       False   \n",
       "4  CCLW.document.i00000012.n0000       False   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://pccommissionflo.imgix.net/uploads/imag...   \n",
       "1  https://pccommissionflo.imgix.net/uploads/imag...   \n",
       "2  https://pccommissionflo.imgix.net/uploads/imag...   \n",
       "3  https://pccommissionflo.imgix.net/uploads/imag...   \n",
       "4  https://pccommissionflo.imgix.net/uploads/imag...   \n",
       "\n",
       "              document_title  \\\n",
       "0  Just Transition Framework   \n",
       "1  Just Transition Framework   \n",
       "2  Just Transition Framework   \n",
       "3  Just Transition Framework   \n",
       "4  Just Transition Framework   \n",
       "\n",
       "                                                text language  type  index  \\\n",
       "0                                               Call       en  Text      0   \n",
       "1  PRESIDENTIAL CLIMATE COMMISSION TOWARDS A JUST...       en  Text      1   \n",
       "2                                                ERO       en  Text      2   \n",
       "3                                            BOMBELA       en  Text      3   \n",
       "4                                          June 2022       en  Text      4   \n",
       "\n",
       "   page_number  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if create_new_sample_csv:\n",
    "    title_df.to_csv(\"justice_subset.csv\", index=False, encoding='utf-8')\n",
    "    df = title_df.copy()\n",
    "elif reload_data == False:\n",
    "    df = pd.read_csv(\"justice_subset.csv\", encoding='utf-8')\n",
    "\n",
    "#Let's shorten the column names\n",
    "df.columns = [col.split('.')[-1] for col in df.columns]\n",
    "\n",
    "print(f\"Total nr of paras: {df.shape[0]}\")\n",
    "print(f\"Total nr of documents: {len(df['document_title'].unique())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Connecting to the LLMs and concept store\n",
    "The LLM classifier we import from src is built using pydantic. That gives us a lot of flexibility and [known models](https://ai.pydantic.dev/api/models/base/#pydantic_ai.models.KnownModelName) to choose from, as long as they are covered by our API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TokenRetrievalError",
     "evalue": "Error when retrieving token from sso: Token has expired and refresh failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTokenRetrievalError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m session \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mSession(profile_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabs\u001b[39m\u001b[38;5;124m\"\u001b[39m, region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meu-west-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m ssm \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWithDecryption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected with Open AI API key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/client.py:601\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/client.py:1056\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     maybe_compress_request(\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m-> 1056\u001b[0m     http, parsed_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1062\u001b[0m     http_response\u001b[38;5;241m=\u001b[39mhttp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1066\u001b[0m )\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/client.py:1080\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1084\u001b[0m             exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   1085\u001b[0m             context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1086\u001b[0m         )\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/endpoint.py:118\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    113\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m         operation_model,\n\u001b[1;32m    116\u001b[0m         request_dict,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/endpoint.py:195\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    193\u001b[0m context \u001b[38;5;241m=\u001b[39m request_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[0;32m--> 195\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_response(\n\u001b[1;32m    197\u001b[0m     request, operation_model, context\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_retry(\n\u001b[1;32m    200\u001b[0m     attempts,\n\u001b[1;32m    201\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception,\n\u001b[1;32m    205\u001b[0m ):\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/endpoint.py:131\u001b[0m, in \u001b[0;36mEndpoint.create_request\u001b[0;34m(self, params, operation_model)\u001b[0m\n\u001b[1;32m    129\u001b[0m     service_id \u001b[38;5;241m=\u001b[39m operation_model\u001b[38;5;241m.\u001b[39mservice_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\n\u001b[1;32m    130\u001b[0m     event_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest-created.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_emitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m prepared_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_request(request)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepared_request\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/hooks.py:412\u001b[0m, in \u001b[0;36mEventAliaser.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    411\u001b[0m     aliased_event_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alias_event_name(event_name)\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_emitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maliased_event_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/hooks.py:256\u001b[0m, in \u001b[0;36mHierarchicalEmitter.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    Emit an event by name with arguments passed as keyword args.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m             handlers.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_emit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/hooks.py:239\u001b[0m, in \u001b[0;36mHierarchicalEmitter._emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers_to_call:\n\u001b[1;32m    238\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling handler \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, event_name, handler)\n\u001b[0;32m--> 239\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend((handler, response))\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_on_response \u001b[38;5;129;01mand\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/signers.py:108\u001b[0m, in \u001b[0;36mRequestSigner.handler\u001b[0;34m(self, operation_name, request, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# This is typically hooked up to the \"request-created\" event\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# from a client's event emitter.  When a new request is created\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# this method is invoked to sign the request.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Don't call this method directly.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/signers.py:191\u001b[0m, in \u001b[0;36mRequestSigner.sign\u001b[0;34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_identity_cache(\n\u001b[1;32m    186\u001b[0m         kwargs,\n\u001b[1;32m    187\u001b[0m         signing_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity_cache\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    188\u001b[0m         signing_context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache_key\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_auth_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnknownSignatureVersionError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m signing_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/signers.py:312\u001b[0m, in \u001b[0;36mRequestSigner.get_auth_instance\u001b[0;34m(self, signing_name, region_name, signature_version, request_credentials, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m frozen_credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     frozen_credentials \u001b[38;5;241m=\u001b[39m \u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frozen_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcredentials\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m frozen_credentials\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mREQUIRES_REGION:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:664\u001b[0m, in \u001b[0;36mRefreshableCredentials.get_frozen_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_frozen_credentials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    631\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return immutable credentials.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    The ``access_key``, ``secret_key``, and ``token`` properties\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m \n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frozen_credentials\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:551\u001b[0m, in \u001b[0;36mRefreshableCredentials._refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     is_mandatory_refresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_needed(\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mandatory_refresh_timeout\n\u001b[1;32m    550\u001b[0m     )\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protected_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_mandatory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_mandatory_refresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:567\u001b[0m, in \u001b[0;36mRefreshableCredentials._protected_refresh\u001b[0;34m(self, is_mandatory)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_protected_refresh\u001b[39m(\u001b[38;5;28mself\u001b[39m, is_mandatory):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;66;03m# precondition: this method should only be called if you've acquired\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;66;03m# the self._refresh_lock.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh_using\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         period_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmandatory\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mandatory \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvisory\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:716\u001b[0m, in \u001b[0;36mCachedCredentialFetcher.fetch_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfetch_credentials\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cached_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:726\u001b[0m, in \u001b[0;36mCachedCredentialFetcher._get_cached_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_from_cache()\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 726\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_credentials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_to_cache(response)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/credentials.py:2243\u001b[0m, in \u001b[0;36mSSOCredentialFetcher._get_credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_provider:\n\u001b[1;32m   2242\u001b[0m     initial_token_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_provider\u001b[38;5;241m.\u001b[39mload_token()\n\u001b[0;32m-> 2243\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43minitial_token_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frozen_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2245\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_loader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_url)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccessToken\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/tokens.py:88\u001b[0m, in \u001b[0;36mDeferredRefreshableToken.get_frozen_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_frozen_token\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frozen_token\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/tokens.py:101\u001b[0m, in \u001b[0;36mDeferredRefreshableToken._refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_lock\u001b[38;5;241m.\u001b[39macquire(block_for_refresh):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protected_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/botocore/tokens.py:128\u001b[0m, in \u001b[0;36mDeferredRefreshableToken._protected_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_expired():\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Fresh credentials should never be expired\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TokenRetrievalError(\n\u001b[1;32m    129\u001b[0m         provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    130\u001b[0m         error_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken has expired and refresh failed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     )\n",
      "\u001b[0;31mTokenRetrievalError\u001b[0m: Error when retrieving token from sso: Token has expired and refresh failed"
     ]
    }
   ],
   "source": [
    "import boto3 #AWS\n",
    "import os\n",
    "\n",
    "#Remember to login with aws sso login --profile labs\n",
    "session = boto3.Session(profile_name=\"labs\", region_name=\"eu-west-1\")\n",
    "ssm = session.client(\"ssm\")\n",
    "api_key = ssm.get_parameter(Name=\"OPENAI_API_KEY\", WithDecryption=True)[\"Parameter\"][\"Value\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "print(\"Connected with Open AI API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flood (Q382)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Span(text='Our basement is underwater.', start_index=16, end_index=26, concept_id='Q382', labellers=['LLMClassifier(flood, model_name=\"gpt-4-turbo\", id=r94z3p2j)'], timestamps=[datetime.datetime(2025, 7, 17, 14, 55, 58, 462296)], id='gdqdtvdz', labelled_text='underwater')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.wikibase import WikibaseSession\n",
    "from src.concept import Concept\n",
    "from src.classifier.llm import LLMClassifier\n",
    "import nest_asyncio #Since we're working on notebookes, we need to handle the async bits\n",
    "nest_asyncio.apply()\n",
    "\n",
    "wikibase = WikibaseSession()\n",
    "flood = wikibase.get_concept('Q382') #Flood\n",
    "print(flood)\n",
    "\n",
    "classifier = LLMClassifier(flood, model_name='gpt-4-turbo')\n",
    "sentence = 'Our basement is underwater.' \n",
    "\n",
    "classifier.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works! Let's explore the basic functionality\n",
    "-  By default, the LLM classifier takes all the info it can find from the concept and puts this in the prompt. But we can also create a custom concept. \n",
    "- Plus, we can run in batches also. Sentences without a predicted span return an empty list. Still a bit unclear to me if batch prediction with nest_asyncio might lead to problems, but it seems OK so far.\n",
    "- Let's also explore the default prompt and play around with that a tiny bit. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Span(text='Here we have a man who is really good at AWS', start_index=15, end_index=44, concept_id=None, labellers=['LLMClassifier(Harrison, model_name=\"gpt-4-turbo\", id=34nzdgz3)'], timestamps=[datetime.datetime(2025, 7, 17, 16, 59, 42, 808248)], id='aptrmezm', labelled_text='man who is really good at AWS')]\n",
      "\n",
      "[Span(text='His name is Harrison. He is a seasoned data scientist.', start_index=12, end_index=20, concept_id=None, labellers=['LLMClassifier(Harrison, model_name=\"gpt-4-turbo\", id=34nzdgz3)'], timestamps=[datetime.datetime(2025, 7, 17, 16, 59, 42, 808409)], id='f7wnybwm', labelled_text='Harrison'), Span(text='His name is Harrison. He is a seasoned data scientist.', start_index=39, end_index=53, concept_id=None, labellers=['LLMClassifier(Harrison, model_name=\"gpt-4-turbo\", id=34nzdgz3)'], timestamps=[datetime.datetime(2025, 7, 17, 16, 59, 42, 808426)], id='bhe4d45t', labelled_text='data scientist')]\n",
      "\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#custom test concept\n",
    "new_concept = Concept(\n",
    "    preferred_label = 'Harrison',\n",
    "    alternative_labels = ['Data scientist'],\n",
    "    description = 'Really good at AWS',\n",
    "    definition = 'The data scientist who is very good at AWS'\n",
    ")\n",
    "\n",
    "classifier = LLMClassifier(new_concept, model_name='gpt-4-turbo') \n",
    "\n",
    "#batch predict\n",
    "sentences = ['Here we have a man who is really good at AWS',\n",
    "             \"His name is Harrison. He is a seasoned data scientist.\",\n",
    "             \"Kalyan is a  nice guy too\"]\n",
    "[print(f\"\\n{c}\") for c in classifier.predict_batch(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT TEMPLATE:\n",
      "\n",
      "You are a specialist climate policy analyst, tasked with identifying mentions of \n",
      "concepts in climate policy documents. You will mark up references to concepts with \n",
      "XML tags.\n",
      "\n",
      "First, carefully review the following description of the concept:\n",
      "\n",
      "<concept_description>\n",
      "{concept_description}\n",
      "</concept_description>\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Read through each passage carefully, thinking about the concept.\n",
      "2. Identify any mentions of the concept, including direct references and related terms.\n",
      "3. Surround each identified mention with <concept> tags.\n",
      "4. If a passage contains multiple instances, each one should be tagged separately.\n",
      "5. If a passage does not contain any instances, it should be reproduced exactly as given, without any additional tags.\n",
      "6. If an entire passage refers to the concept without specific mentions, the entire passage should be wrapped in a <concept> tag.\n",
      "7. The input text must be reproduced exactly, down to the last character, only adding concept tags.\n",
      "\n",
      "\n",
      "\n",
      "SYSTEM PROMPT:\n",
      "\n",
      "You are a specialist climate policy analyst, tasked with identifying mentions of \n",
      "concepts in climate policy documents. You will mark up references to concepts with \n",
      "XML tags.\n",
      "\n",
      "First, carefully review the following description of the concept:\n",
      "\n",
      "<concept_description>\n",
      "# Harrison\n",
      "\n",
      "## Description\n",
      "\n",
      "Really good at AWS\n",
      "\n",
      "## Definition\n",
      "\n",
      "The data scientist who is very good at AWS\n",
      "\n",
      "## Alternative labels, synonyms, acronyms, and related terms\n",
      "\n",
      "- Data scientist\n",
      "</concept_description>\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Read through each passage carefully, thinking about the concept.\n",
      "2. Identify any mentions of the concept, including direct references and related terms.\n",
      "3. Surround each identified mention with <concept> tags.\n",
      "4. If a passage contains multiple instances, each one should be tagged separately.\n",
      "5. If a passage does not contain any instances, it should be reproduced exactly as given, without any additional tags.\n",
      "6. If an entire passage refers to the concept without specific mentions, the entire passage should be wrapped in a <concept> tag.\n",
      "7. The input text must be reproduced exactly, down to the last character, only adding concept tags.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Keep in mind the difference between the template prompt and the fully filled out system prompt\n",
    "print(\"PROMPT TEMPLATE:\")\n",
    "print(classifier.system_prompt_template)\n",
    "print(\"\\n\\nSYSTEM PROMPT:\")\n",
    "print(classifier.system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some justice concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's figure out how long this really takes\n",
    "import time\n",
    "df.dropna(subset = 'text', inplace = True)\n",
    "small_df = df.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicition\n"
     ]
    },
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Exceeded maximum retries (1) for result validation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_result.py:212\u001b[0m, in \u001b[0;36mResultTool.validate\u001b[0;34m(self, tool_call, allow_partial, wrap_validation_errors)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_call\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 212\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperimental_allow_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyd_allow_partial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic/type_adapter.py:468\u001b[0m, in \u001b[0;36mTypeAdapter.validate_json\u001b[0;34m(self, data, strict, context, experimental_allow_partial, by_alias, by_name)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    465\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidate-by-alias-and-name-false\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_allow_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMResponse\nmarked_up_text\n  Field required [type=missing, input_value={'text': 'Industry throug... 'distributive justice'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nreasoning\n  Field required [type=missing, input_value={'text': 'Industry throug... 'distributive justice'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mToolRetryError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:440\u001b[0m, in \u001b[0;36mCallToolsNode._handle_tool_calls\u001b[0;34m(self, ctx, tool_calls)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[43mresult_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _validate_result(result_data, ctx, call)\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_result.py:222\u001b[0m, in \u001b[0;36mResultTool.validate\u001b[0;34m(self, tool_call, allow_partial, wrap_validation_errors)\u001b[0m\n\u001b[1;32m    217\u001b[0m     m \u001b[38;5;241m=\u001b[39m _messages\u001b[38;5;241m.\u001b[39mRetryPromptPart(\n\u001b[1;32m    218\u001b[0m         tool_name\u001b[38;5;241m=\u001b[39mtool_call\u001b[38;5;241m.\u001b[39mtool_name,\n\u001b[1;32m    219\u001b[0m         content\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39merrors(include_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    220\u001b[0m         tool_call_id\u001b[38;5;241m=\u001b[39mtool_call\u001b[38;5;241m.\u001b[39mtool_call_id,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ToolRetryError(m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mToolRetryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting predicition\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m prediction_spans \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m tseconds \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtseconds\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/src/classifier/llm.py:199\u001b[0m, in \u001b[0;36mLLMClassifier.predict_batch\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    195\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mset_event_loop(loop)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Run all predictions in the batch in parallel\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     responses: \u001b[38;5;28mlist\u001b[39m[AgentRunResult[LLMResponse]] \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# Only close the loop if we created it\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop():\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/asyncio/tasks.py:234\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/src/classifier/llm.py:188\u001b[0m, in \u001b[0;36mLLMClassifier.predict_batch.<locals>.run_predictions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_predictions\u001b[39m():\n\u001b[1;32m    182\u001b[0m     async_responses \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    184\u001b[0m             text, model_settings\u001b[38;5;241m=\u001b[39mModelSettings(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed)\n\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[1;32m    187\u001b[0m     ]\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m gather(\u001b[38;5;241m*\u001b[39masync_responses)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/agent.py:329\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_name(inspect\u001b[38;5;241m.\u001b[39mcurrentframe())\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\n\u001b[1;32m    320\u001b[0m     user_prompt\u001b[38;5;241m=\u001b[39muser_prompt,\n\u001b[1;32m    321\u001b[0m     result_type\u001b[38;5;241m=\u001b[39mresult_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m     usage\u001b[38;5;241m=\u001b[39musage,\n\u001b[1;32m    328\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent_run\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe graph run did not finish properly\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/agent.py:1442\u001b[0m, in \u001b[0;36mAgentRun.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__anext__\u001b[39m(\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _agent_graph\u001b[38;5;241m.\u001b[39mAgentNode[AgentDepsT, ResultDataT] \u001b[38;5;241m|\u001b[39m End[FinalResult[ResultDataT]]:\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     next_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_run\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph\u001b[38;5;241m.\u001b[39mis_agent_node(next_node):\n\u001b[1;32m   1444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_graph/graph.py:782\u001b[0m, in \u001b[0;36mGraphRun.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node, End):\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node)\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_graph/graph.py:760\u001b[0m, in \u001b[0;36mGraphRun.next\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistence\u001b[38;5;241m.\u001b[39mrecord_run(node_snapshot_id):\n\u001b[1;32m    759\u001b[0m         ctx \u001b[38;5;241m=\u001b[39m GraphRunContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeps)\n\u001b[0;32m--> 760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m node\u001b[38;5;241m.\u001b[39mrun(ctx)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node, End):\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_snapshot_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node\u001b[38;5;241m.\u001b[39mget_snapshot_id()\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:373\u001b[0m, in \u001b[0;36mCallToolsNode.run\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m, ctx: GraphRunContext[GraphAgentState, GraphAgentDeps[DepsT, NodeRunEndT]]\n\u001b[1;32m    372\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ModelRequestNode[DepsT, NodeRunEndT], End[result\u001b[38;5;241m.\u001b[39mFinalResult[NodeRunEndT]]]:  \u001b[38;5;66;03m# noqa UP007\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(ctx):\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe stream should set `self._next_node` before it ends\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/contextlib.py:206\u001b[0m, in \u001b[0;36m_AsyncGeneratorContextManager.__aexit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:387\u001b[0m, in \u001b[0;36mCallToolsNode.stream\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m stream\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Run the stream to completion if it was not finished:\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _event \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:424\u001b[0m, in \u001b[0;36mCallToolsNode._run_stream\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedModelBehavior(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived empty model response\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events_iterator \u001b[38;5;241m=\u001b[39m _run_stream()\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events_iterator:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:414\u001b[0m, in \u001b[0;36mCallToolsNode._run_stream.<locals>._run_stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# At the moment, we prioritize at least executing tool calls if they are present.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# In the future, we'd consider making this configurable at the agent or run level.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# This accounts for cases like anthropic returns that might contain a text response\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# and a tool call response, where the text response just indicates the tool call will happen.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_calls:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_tool_calls(ctx, tool_calls):\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m texts:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# No events are emitted during the handling of text responses, so we don't need to yield anything\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:445\u001b[0m, in \u001b[0;36mCallToolsNode._handle_tool_calls\u001b[0;34m(self, ctx, tool_calls)\u001b[0m\n\u001b[1;32m    441\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _validate_result(result_data, ctx, call)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _result\u001b[38;5;241m.\u001b[39mToolRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# TODO: Should only increment retry stuff once per node execution, not for each tool call\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m#   Also, should increment the tool-specific retry count rather than the run retry count\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_result_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(e\u001b[38;5;241m.\u001b[39mtool_retry)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/knowledge-graph/.venv/lib/python3.10/site-packages/pydantic_ai/_agent_graph.py:71\u001b[0m, in \u001b[0;36mGraphAgentState.increment_retries\u001b[0;34m(self, max_result_retries)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries \u001b[38;5;241m>\u001b[39m max_result_retries:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedModelBehavior(\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExceeded maximum retries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_result_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) for result validation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m: Exceeded maximum retries (1) for result validation"
     ]
    }
   ],
   "source": [
    "wikibase = WikibaseSession()\n",
    "distributive = wikibase.get_concept('Q911') #Distributive justice\n",
    "\n",
    "classifier = LLMClassifier(distributive, model_name='gpt-3.5-turbo')\n",
    "\n",
    "print(\"Starting predicition\")\n",
    "t0 = time.time()\n",
    "prediction_spans = classifier.predict_batch(small_df['text'].astype(str))\n",
    "tseconds = time.time()-t0\n",
    "print(f\"Finished in {tseconds:.2f} seconds\")\n",
    "print(f\"That's {tseconds/len(small_df):.3f} s per passage\\n\\nPositive examples:\")\n",
    "\n",
    "for prediction in prediction_spans:\n",
    "    if len(prediction)>0:\n",
    "        for p in prediction:\n",
    "            print(p.text)\n",
    "            print(f\"=> {p.labelled_text}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, I draw the following conclusions:\n",
    "- not bad at all! \n",
    "- it seems likely we'll want to do some filtering before feeding it to the LLM (but we wanted to do that anyway to limit monetary and enviornmental costs)\n",
    "- it's quick enough that this filtering can be relatively coarse though\n",
    "- my Spanish isn't great but it seems to do OK there too. Still, as we translate to English anyway, probably better to limit to that here.\n",
    "\n",
    "Further, it would be good to tweak the prompt template somewhat:\n",
    "- the spans are often on the short side. Ideally, it should label modifiers on the main word too. \n",
    "- it's probably too permissive. It's broadly good that it is picking up on justice \"vibes\", but it is not currently distinguishing between the specific justice type. Unsure if this entirely on the template or on the concept description, but we should encourage it to be stricter. \n",
    "- as a more specific case, I think it needs to ignore negative examples (i.e. injustices). Somewhat debatable & this definitely seems like something we'll want to decide on a concept-by-concept basis, so let's add that to the definition instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare a few different prompts and also try other (simpler?) models\n",
    "\n",
    "setups = {\n",
    "    \"current\": LLMClassifier(distributive, \n",
    "                             model_name='gpt-4-turbo',\n",
    "                            system_prompt_template=\n",
    "                             classifier.system_prompt_template  # Current template\n",
    "    ),\n",
    "\n",
    "\n",
    "    \"strict\":LLMClassifier(distributive,\n",
    "                           model_name='gpt-4-turbo',\n",
    "                           system_prompt_template=\"\"\"\n",
    "    You are a specialist climate policy analyst, tasked with identifying mentions of \n",
    "    concepts in climate policy documents. You will mark up references to concepts with \n",
    "    XML tags.  \n",
    "\n",
    "    First, carefully review the following description of the concept. These tags will be used to investigate fine-grained distinctions so it is essential that you base your judgement on the nuances of the description.\n",
    "\n",
    "    <concept_description>\n",
    "    {concept_description}\n",
    "    </concept_description>\n",
    "\n",
    "    Instructions:\n",
    "    1. Be very strict in identifying concept mentions - read each passage carefully and only tag if you are highly confident that the passage is relevant to an expert, accounting for variations in language.\n",
    "    2. Identify any mentions of the concept, and include surrounding context in the tags also if these are relevant to the concept. Again, be strict but allow for variations in language. \n",
    "    3. Surround each identified mention with <concept> tags.\n",
    "    4. If a passage contains multiple instances, each one should be tagged separately.\n",
    "    5. If a passage does not contain any instances, it should be reproduced exactly as given, without any additional tags.\n",
    "    6. If an entire passage refers to the concept without specific mentions, the entire passage should be wrapped in a <concept> tag.\n",
    "    7. Do not tag negative examples or injustices unless the need for justice is made explicit or is heavily implied\n",
    "    8. The input text must be reproduced exactly, down to the last character, only adding concept tags.\n",
    "    \"\"\"),\n",
    "\n",
    "    \"lenient\": LLMClassifier(distributive,\n",
    "                           model_name='gpt-4-turbo',\n",
    "                           system_prompt_template = \"\"\"\n",
    "    You are a specialist climate policy analyst, tasked with identifying mentions of \n",
    "    concepts in climate policy documents. You will mark up references to concepts with \n",
    "    XML tags.\n",
    "\n",
    "    First, carefully review the following description of the concept:\n",
    "\n",
    "    <concept_description>\n",
    "    {concept_description}\n",
    "    </concept_description>\n",
    "\n",
    "    Instructions:\n",
    "    1. Be inclusive in identifying concept mentions - tag if there's a reasonable connection,  allowing for differences in language and understandings of the concept\n",
    "    2. Include surrounding context in tags to capture full meaning\n",
    "    3. Surround each identified mention with <concept> tags.\n",
    "    4. If a passage contains multiple instances, each one should be tagged separately.\n",
    "    5. If a passage does not contain any instances, it should be reproduced exactly as given, without any additional tags.\n",
    "    6. If an entire passage refers to the concept without specific mentions, the entire passage should be wrapped in a <concept> tag\n",
    "    7. Also tag negative instances of the concept -- i.e. tag injustices and situations where justice is called for. \n",
    "    8. The input text must be reproduced exactly, down to the last character, only adding concept tags. \n",
    "    \"\"\"\n",
    "    ), \n",
    "\n",
    "    \n",
    "    \"rules\": LLMClassifier(distributive,\n",
    "                           model_name='gpt-4-turbo',\n",
    "                           system_prompt_template = \"\"\"\n",
    "    You are a specialist climate policy analyst, tasked with identifying mentions of \n",
    "    concepts in climate policy documents. You will mark up references to concepts with \n",
    "    XML tags.\n",
    "\n",
    "    First, carefully review the following description of the concept:\n",
    "\n",
    "    <concept_description>\n",
    "    {concept_description}\n",
    "    </concept_description>\n",
    "\n",
    "    Instructions:\n",
    "    1. First, think about the core of the description you have just read. Distill this into key characteristics, thinking carefully on when a policy expert would include and exclude.\n",
    "    2. Keep these inclusion and exclusion criteria in mind and assign your tags, being strict to only include mentions that are relevant to the core idea of the concept.\n",
    "    3. Surround each identified mention with <concept> tags.\n",
    "    4. If a passage contains multiple instances, each one should be tagged separately.\n",
    "    5. If a passage does not contain any instances, it should be reproduced exactly as given, without any additional tags.\n",
    "    6. If an entire passage refers to the concept without specific mentions, the entire passage should be wrapped in a <concept> tag\n",
    "    7. If the context is important to understand the meaning of the passage, be inclusive and include this context within the tags.\n",
    "    7. The input text must be reproduced exactly, down to the last character, only adding concept tags. \n",
    "    \"\"\"\n",
    "    ),\n",
    "\n",
    "\n",
    "    # Different models\n",
    "    #'gemini_pro': LLMClassifier(distributive, model_name='gemini-2.5-pro-exp-03-25'),\n",
    "    #'gemini_flash': LLMClassifier(distributive, model_name = 'gemini-1.5-flash-002'),\n",
    "    #'gemini_thinking': LLMClassifier(distributive, model_name = \"gemini-2.0-flash-thinking-exp-01-21\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's write some helper functions to make my life easier \n",
    "#and then use that to set up some experiments\n",
    "#First, let's create a function to get tagged passages in a readable format\n",
    "def get_tagged_passages(classifier, texts):\n",
    "    results = []\n",
    "    # Use predict_batch instead of individual predict calls\n",
    "    all_spans = classifier.predict_batch(texts)\n",
    "    \n",
    "    # Match spans with their original texts\n",
    "    for text, spans in notebook_tqdm.tqdm(zip(texts, all_spans), \n",
    "                                        total=len(texts), \n",
    "                                        desc=\"Processing tagged passages\"):\n",
    "        if spans:  # Only include texts that got tagged\n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'tagged_spans': [span.labelled_text for span in spans]\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def compare_setups(setups, sample_texts):\n",
    "    \"\"\"\n",
    "    setups: dict of {setup_name: classifier}\n",
    "    sample_texts: list of texts to test\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for setup_name, classifier in notebook_tqdm.tqdm(setups.items(), \n",
    "                                                   desc=\"Comparing setups\"):\n",
    "        tagged = get_tagged_passages(classifier, sample_texts)\n",
    "        results[setup_name] = {\n",
    "            'n_tagged': len(tagged),\n",
    "            'tagged_passages': tagged\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "def create_comparison_table(results):\n",
    "    \"\"\"\n",
    "    Create a comparison table that includes both quantitative and qualitative data.\n",
    "    \"\"\"\n",
    "    # Initialize dictionary to store the data\n",
    "    comparison_data = {\n",
    "        'text': sample_texts,  # Original texts\n",
    "    }\n",
    "    \n",
    "    # Add columns for each setup\n",
    "    for setup_name, result in results.items():\n",
    "        # Create a dictionary mapping texts to their tagged spans\n",
    "        text_to_spans = {p['text']: p['tagged_spans'] for p in result['tagged_passages']}\n",
    "        \n",
    "        # Add both the binary tag and the actual spans\n",
    "        comparison_data[f'{setup_name}_tagged'] = [1 if text in text_to_spans else 0 for text in sample_texts]\n",
    "        comparison_data[f'{setup_name}_spans'] = [text_to_spans.get(text, []) for text in sample_texts]\n",
    "    \n",
    "    # Create DataFrame only once at the end\n",
    "    return pd.DataFrame(comparison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing setups:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tagged passages: 100%|| 400/400 [00:00<00:00, 603279.97it/s]\n",
      "Processing tagged passages: 100%|| 400/400 [00:00<00:00, 1093690.74it/s]\n",
      "Processing tagged passages: 100%|| 400/400 [00:00<00:00, 821204.89it/s]\n",
      "Processing tagged passages: 100%|| 400/400 [00:00<00:00, 584164.90it/s]\n",
      "Comparing setups: 100%|| 4/4 [00:56<00:00, 14.07s/it]\n"
     ]
    }
   ],
   "source": [
    "#Run the comparison\n",
    "sample_texts = df[df['language'] == 'en'].sample(n=400, random_state=420)['text'].tolist()\n",
    "sample_texts = [str(t) for t in sample_texts]\n",
    "results = compare_setups(setups, sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total passages tagged by each setup:\n",
      "current_tagged    44\n",
      "strict_tagged     34\n",
      "lenient_tagged    46\n",
      "rules_tagged      47\n",
      "dtype: int64\n",
      "\n",
      "Passages where setups disagree:\n",
      "\n",
      "Original text:  In 2016, JMD collaborated with Bureau Sustainability Program Managers and facilities personnel to evaluate all DOJ-owned facilities for vulnerabilities to coastal and inland flooding, extreme heat, drought, and wildfire using the DOJ Facility Climate Adaptation Checklist.\n",
      "current identified: ['vulnerabilities to coastal and inland flooding, extreme heat, drought, and wildfire']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['vulnerabilities to coastal and inland flooding, extreme heat, drought, and wildfire']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: Within renewables, employment opportunities are diverse: the number of jobs per MW created in the solar energy sector is significant, although in Europe it is mainly linked to installation; wind power generates fewer jobs per MW, but leads to a greater generation of industrial employment in Spain; and biomass, developed with sustainability criteria, offers interesting rural employment opportunities and possibilities of supplementing agricultural income and thus making the maintenance of farms more attractive, which can help to slow down the process of depopulation.\n",
      "current identified: ['rural employment opportunities and possibilities of supplementing agricultural income and thus making the maintenance of farms more attractive, which can help to slow down the process of depopulation']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['rural employment opportunities and possibilities of supplementing agricultural income and thus making the maintenance of farms more attractive, which can help to slow down the process of depopulation']\n",
      "\n",
      "Original text: \"(II) the registered apprenticeship program fails to respond to such request within 5 business days after the date on which such registered apprenticeship program received such request. \"(iii) INTENTIONAL DISREGARD .- If the Secretary determines that any failure described in subclause (i)(II) is due to intentional disregard of the require- ments under subparagraphs (A) and (C), subclause (i)(II) shall be applied by substituting '$500' for '$50' in item (aa) thereof. \"(E) DEFINITIONS .- For purposes of this paragraph- \"(i) LABOR HOURS .- The term 'labor hours'- \"(I) means the total number of hours devoted to the performance of construction, alteration, or repair work by any individual employed by the taxpayer or by any contractor or subcontractor, and\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['intentional disregard of the require- ments under subparagraphs (A) and (C)']\n",
      "\n",
      "Original text: far reaching threat to people and communities around the world and has implications for the full enjoyment of human rights.\" In the Paris Agreement, parties to the UN Framework Convention on Climate Change (UNFCCC) acknowledged that they should - when taking action to address climate change - respect, promote and consider their respective obligations with regard to human rights. This includes the right to health, the rights of indigenous peoples, local communities, migrants, children, persons with disabilities and people in vulnerable situations and the right to development, as well as gender equality, the empowerment of women and intergenerational equity. Tackling loss and damage will require a human-rights centred approach that promotes justice and equity.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: ['vulnerable situations', 'intergenerational equity', 'Tackling loss and damage will require a human-rights centred approach that promotes justice and equity']\n",
      "lenient identified: ['communities around the world', 'right to health, the rights of indigenous peoples, local communities, migrants, children, persons with disabilities and people in vulnerable situations', 'human-rights centred approach that promotes justice and equity']\n",
      "rules identified: ['people in vulnerable situations', 'intergenerational equity', 'Tackling loss and damage will require a human-rights centred approach that promotes justice and equity']\n",
      "\n",
      "Original text: The first step is to enforce building regulations to ensure that they are effective. Enforcement includes monitoring and issuing penalties for noncompliance. Penalties may be financial; they can also include options such as retraction of permits for leasing. Sufficient capacity is needed for regulatory organizations to be effective. Reg- ulators need to have sufficient funds and personnel for monitoring, and personnel require appropriate training on new and changing regulations.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: ['Penalties may be financial']\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['Penalties may be financial']\n",
      "\n",
      "Original text: Beyond carbon pricing, governments, as one of the main consumers of industrial goods, can also incentivize companies to produce low-emissions materials. In the United States, for instance, approximately 18 percent and 50 percent of annual CO2 emissions associated with steel and cement consumption, respectively, are associated with public construction (Hasanbeigi et al. 2021). Green or sustainable procurement policies that require public entities to purchase low-carbon industrial products at a premium create a guaranteed market for these prod- ucts. These policies therefore reduce the financial risks of transitioning from conventional, emissions-intensive production processes to those that are more aligned with\n",
      "current identified: [NO TAGS]\n",
      "strict identified: ['Green or sustainable procurement policies that require public entities to purchase low-carbon industrial products at a premium create a guaranteed market for these prod- ucts. These policies therefore reduce the financial risks of transitioning from conventional, emissions-intensive production processes to those that are more aligned with']\n",
      "lenient identified: ['Green or sustainable procurement policies that require public entities to purchase low-carbon industrial products at a premium create a guaranteed market for these prod- ucts. These policies therefore reduce the financial risks of transitioning from conventional, emissions-intensive production processes to those that are more aligned with']\n",
      "rules identified: ['Green or sustainable procurement policies that require public entities to purchase low-carbon industrial products at a premium create a guaranteed market for these prod- ucts. These policies therefore reduce the financial risks of transitioning from conventional, emissions-intensive production processes to those that are more aligned with']\n",
      "\n",
      "Original text: a) Range of values depending on advanced or emerging economies with or without Net Zero commitments. For low-income economies a lower cost is expected.\n",
      "current identified: ['low-income economies a lower cost is expected']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['low-income economies a lower cost is expected']\n",
      "\n",
      "Original text: :unselected: In the Pacific a key strategy to mitigate climate change is the active revitalization of traditional technologies connected to agriculture, aquaculture, and natural resource management. In Hawai'i, there is a strong effort to restore the sustainable loko i'a or fishpond system to replace extractive and unstable commercial fishing. As food production systems, loko i'a have the potential to produce thousands of pounds of sustainable protein annually while mitigating coral bleaching, reef death, beach erosion, fish population overkills, and other imbalances in the marine ecosystem. The Native Hawaiian community has recently created a streamlined permitting process to make the restoration of ponds more viable and achievable by the native community.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['imbalances in the marine ecosystem']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text:  Risks related to the violation of human rights\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['Risks related to the violation of human rights']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text:  In Ecuador, Indigenous Peoples have successfully prevented the advance of oil extraction through peaceful resistance, mainly led by women. The Ecuadorian Constitution recognizes the rights of peoples and nature. Economic, social and environmental policies must start from these rights, which must take precedence over the rights of investors.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['Indigenous Peoples have successfully prevented the advance of oil extraction through peaceful resistance, mainly led by women', 'Economic, social and environmental policies must start from these rights, which must take precedence over the rights of investors.']\n",
      "\n",
      "Original text: In this way, the jobs that coal plants will no longer provide, whose number in 2018 reached 4,390 direct jobs and nearly 9,500 indirect jobs (2), will be greatly increased by the development of the renewable energy industry and green hydrogen, transforming the energy transition into an important source of new jobs for the country.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['energy transition into an important source of new jobs for the country']\n",
      "\n",
      "Original text: Support for areas of fair transition agreements and mining areas\n",
      "current identified: ['fair transition']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['fair transition agreements']\n",
      "rules identified: ['fair transition agreements and mining areas']\n",
      "\n",
      "Original text: In addition to the CN commitment to 2050, along with assuming the Presidency of COP 25 and as part of the commitments established in the Paris Agreement, Chile submitted to the UNFCCC6 the update of its Nationally Determined Contribution (NDC) in April 2020. It incorporates a Social Pillar of Just Transition and Sustainable Development that establishes a &quot;Just transition: particularly focused on the decarbonization process of the electricity generation matrix, the difficulties and needs of those who are particularly vulnerable must be analyzed, recognizing, respecting and promoting the obligations related to a just transition towards a low-carbon and climate-resilient economy&quot; and specifically commits to &quot;Develop by 2021 a &quot;Just Transition Strategy&quot;, which safeguards the rights of the most vulnerable in the decarbonization process of the energy matrix and that has active citizen participation in its design and implementation.&quot;\n",
      "current identified: ['Just Transition', 'Just transition: particularly focused on the decarbonization process of the electricity generation matrix, the difficulties and needs of those who are particularly vulnerable must be ', 'sition towards ', 'erable in the d']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: Sustainable Development, Poverty Eradication and Reducing Inequalities\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['Poverty Eradication', 'Reducing Inequalities']\n",
      "\n",
      "Original text: 18. In the same lines, safeguarding biodiversity and ecosystems has been described by the IPCC as \"fundamental to climate resilient development\", in light of the roles they play in adaptation and mitigation14. Conversely, the limited capacity of biodiversity and ecosystems to adapt to increasing global warming levels poses a threat to the possibility to achieve climate resilient development, since such limited capacity in the face of current and future global warming translates into a decline of the effectiveness of ecosystem-based adaptation and approaches to climate change mitigation based on\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['decline of the effectiveness of ecosystem-based adaptation and approaches to climate change mitigation based on']\n",
      "rules identified: ['decline of the effectiveness of ecosystem-based adaptation and approaches to climate change mitigation based on']\n",
      "\n",
      "Original text:  Modernising public employment services, with a strong focus on the quality of the work experience, as well as on the social value created, informed by local community priorities\n",
      "current identified: ['social value created, informed by local community priorities']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['social value created, informed by local community priorities']\n",
      "rules identified: ['social value created, informed by local community priorities']\n",
      "\n",
      "Original text: Regular interactions with Consumer Associations (CAs) to: present results, objectives and future strategies // meetings and workshops with Presidents, General Secretaries and Energy Managers of national and local CAs on issues related to sustainability, energy transition, circular economy, digitization and commercial initiatives // share results on protocol monitoring for the prevention of unsolicited activations // improve customer satisfaction and service quality, also through dedicated channels and reserved web area\n",
      "current identified: ['sustainability, energy transition']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['sustainability, energy transition']\n",
      "rules identified: ['sustainability, energy transition']\n",
      "\n",
      "Original text: While the projected impacts in select at-risk value chains and sectors are extremely concerning, it is important to recognise that there are also signifi- cant opportunities in the transition-to improve the well-being of the economy, where people live and work in meaningful and positive relationships with each other and the planet.\n",
      "current identified: ['transition-to improve the well-being of the economy, where people live and work in meaningful and positive relationships with each other and the planet']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['well-being of the economy, where people live and work in meaningful and positive relationships with each other and the planet']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: Reducing underlying vulnerabilities\n",
      "current identified: ['vulnerabilities']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['vulnerabilities']\n",
      "rules identified: ['vulnerabilities']\n",
      "\n",
      "Original text:  Pervasive conditions in which domestic economies are dominated by foreign investments and transnational corporations, inordinately dependent on imports, and primarily oriented to providing cheap labor and exports of cheap raw materials and semi-finished products. All these conditions, of course, are legacies of colonialism.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['legacies of colonialism']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: Fleurbaey, M. et al., 2014: Sustainable development and equity. In: Climate Change 2014: Mitigation of Climate Change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change [Edenhofer, O., R. Pichs-Madruga, Y. Sokona, E. Farahani, S. Kadner, K. Seyboth, A. Adler, I. Baum, S. Brunner, P. Eickemeier, B. Kriemann, J. Savolainen, S. Schlomer, C. Stechow, T. Zwickel, and J.C. Minx (eds.)]. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA, pp. 283-350. Ford, J.D. et al., 2016: Community-based adaptation research in the Canadian Arctic. Wiley Interdisciplinary Reviews: Climate Change, 7(2), 175-191, doi:10.1002/wcc.376. Francis, R., P. Weston, and J. Birch, 2015: The social, environmental and economics benefits of Farmer Managed Natural Regeneration (FMNR). World Vision Australia, Melbourne, Australia, 44 pp.\n",
      "current identified: ['equity']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['equity']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: (B), with respect to an authorized generic drug, in applying the provisions of this part, such authorized generic drug and such listed drug or such product shall be treated as the same qualifying single source drug. \"(B) AUTHORIZED GENERIC DRUG DEFINED .- For pur- poses of this paragraph, the term 'authorized generic drug' means- \"(i) in the case of a drug, an authorized generic drug (as such term is defined in section 505(t)(3) of the Federal Food, Drug, and Cosmetic Act); and \"(ii) in the case of a biological product, a product that- \"(I) has been licensed under section 351(a) of such Act; and \"(II) is marketed, sold, or distributed directly or indirectly to retail class of trade under a dif- ferent labeling, packaging (other than repackaging as the reference product in blister packs, unit doses, or similar packaging for use in institutions), product code, labeler code, trade name, or trade mark than the reference product. \"(3) EXCLUSIONS .- In this part, the term 'qualifying single source drug' does not include any of the following: \"(A) CERTAIN ORPHAN DRUGS .- A drug that is des- ignated as a drug for only one rare disease or condition under section 526 of the Federal Food, Drug, and Cosmetic Act and for which the only approved indication (or indica- tions) is for such disease or condition. \"(B) LOW SPEND MEDICARE DRUGS .- A drug or biological product with respect to which the total expenditures under parts B and D of title XVIII, as determined by the Secretary in accordance with subsection (d)(3)(B)- \"(i) with respect to initial price applicability year 2026, is less than, during the period beginning on June 1, 2022, and ending on May 31, 2023, $200,000,000; \"(ii) with respect to initial price applicability year 2027, is less than, during the most recent 12-month period applicable under subparagraphs (A) and (B) of subsection (d)(1) for such year, the dollar amount speci- fied in clause (i) increased by the annual percentage increase in the consumer price index for all urban consumers (all items; United States city average) for the period beginning on June 1, 2023, and ending on September 30, 2024; or \"(iii) with respect to a subsequent initial price applicability year, is less than, during the most recent 12-month period applicable under subparagraphs (A) and (B) of subsection (d)(1) for such year, the dollar amount specified in this subparagraph for the previous initial price applicability year increased by the annual percentage increase in such consumer price index for the 12-month period ending on September 30 of the year prior to the year of the selected drug publication date with respect to such subsequent initial price applicability year.\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['LOW SPEND MEDICARE DRUGS .- A drug or biological product with respect to which the total expenditures under parts B and D of title XVIII, as determined by the Secretary in accordance with subsection (d)(3)(B)- \"(i) with respect to initial price applicability year 2026, is less than, during the period beginning on June 1, 2022, and ending on May 31, 2023, $200,000,000; \"(ii) with respect to initial price applicability year 2027, is less than, during the most recent 12-month period applicable under subparagraphs (A) and (B) of subsection (d)(1) for such year, the dollar amount speci- fied in clause (i) increased by the annual percentage increase in the consumer price index for all urban consumers (all items; United States city average) for the period beginning on June 1, 2023, and ending on September 30, 2024; or \"(iii) with respect to a subsequent initial price applicability year, is less than, during the most recent 12-month period applicable under subparagraphs (A) and (B) of subsection (d)(1) for such year, the dollar amount specified in this subparagraph for the previous initial price applicability year increased by the annual percentage increase in such consumer price index for the 12-month period ending on September 30 of the year prior to the year of the selected drug publication date with respect to such subsequent initial price applicability year.']\n",
      "\n",
      "Original text: INSTITUTE FOR JUST TRANSITION\n",
      "current identified: ['JUST TRANSITION']\n",
      "strict identified: ['JUST TRANSITION']\n",
      "lenient identified: ['INSTITUTE FOR JUST TRANSITION']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: Sustainable Development, Poverty Eradication and Reducing Inequalities\n",
      "current identified: [NO TAGS]\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: ['Poverty Eradication', 'Reducing Inequalities']\n",
      "\n",
      "Original text:  It is obvious that justice within nations is the flip side of justice between nations, and that we will not have one without the other.\n",
      "current identified: ['justice within nations is the flip side of justice between nations']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['justice within nations is the flip side of justice between nations']\n",
      "rules identified: [NO TAGS]\n",
      "\n",
      "Original text: in the technology or an increase in the value of the technology as more people adopt it, can also push technology adoption past a tipping point. Oftentimes, seemingly small changes in these factors can trigger these disproportionately large responses within\n",
      "current identified: ['disproportionately large responses']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: ['disproportionately large responses']\n",
      "rules identified: ['disproportionately large responses']\n",
      "\n",
      "Original text: bioenergy production could lead to the creation of\n",
      "jobs, as well as higher farm wages and more diversified\n",
      "for farmers. Modern energy access can make marginal\n",
      "cultivable, thus potentially generating on-farm jobs and\n",
      "the other hand, greater farm mechanization can also\n",
      "However, large-scale bioenergy production could alter\n",
      "of global agricultural markets in a way that is, potentially,\n",
      "to small-scale food producers. The distributional effects of\n",
      "production are underexplored in the literature (McCollum et\n",
      "current identified: ['distributional effects']\n",
      "strict identified: [NO TAGS]\n",
      "lenient identified: [NO TAGS]\n",
      "rules identified: [NO TAGS]\n"
     ]
    }
   ],
   "source": [
    "# Create and display the comparison table\n",
    "comparison_table = create_comparison_table(results)\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"Total passages tagged by each setup:\")\n",
    "print(comparison_table[[col for col in comparison_table.columns if col.endswith('_tagged')]].sum())\n",
    "\n",
    "# Show passages where setups disagree\n",
    "print(\"\\nPassages where setups disagree:\")\n",
    "disagreements = comparison_table[comparison_table[[col for col in comparison_table.columns if col.endswith('_tagged')]].nunique(axis=1) > 1]\n",
    "\n",
    "# For each disagreeing passage, show the different spans identified\n",
    "for _, row in disagreements.iterrows():\n",
    "    print(\"\\nOriginal text:\", row['text'])\n",
    "    for setup in setups.keys():\n",
    "        if row[f'{setup}_tagged']:\n",
    "            print(f\"{setup} identified:\", row[f'{setup}_spans'])\n",
    "        else:\n",
    "            print(f\"{setup} identified: [NO TAGS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table.to_csv(\"350513_comparison_table_very_coarse.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
